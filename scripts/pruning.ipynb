{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dac\n",
    "from dac.model.dac import EncoderBlock, DecoderBlock, ResidualUnit\n",
    "from dac.nn.layers import Snake1d\n",
    "from audiotools import AudioSignal\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\")\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAC(\n",
       "  (encoder): Encoder(\n",
       "    (block): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       "  (quantizer): ResidualVectorQuantize(\n",
       "    (quantizers): ModuleList(\n",
       "      (0-8): 9 x VectorQuantize(\n",
       "        (in_proj): Conv1d(1024, 8, kernel_size=(1,), stride=(1,))\n",
       "        (out_proj): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (codebook): Embedding(1024, 8)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (model): Sequential(\n",
       "      (0): Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "nn.Conv1d here\n",
      "1 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "2 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "3 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "4 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "5 Snake1d()\n",
      "6 Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "nn.Conv1d here\n"
     ]
    }
   ],
   "source": [
    "conv_layers = []\n",
    "\n",
    "for idx, layer in enumerate(model.encoder.block):\n",
    "    print(idx, layer)\n",
    "    if isinstance(layer, nn.Conv1d):\n",
    "        print(\"nn.Conv1d here\")\n",
    "        conv_layers.append(layer)\n",
    "    elif isinstance(layer, EncoderBlock):\n",
    "        encoder_block_layers = layer.block\n",
    "        print(\"encoder block here\")\n",
    "        for encoder_block_layer in encoder_block_layers:\n",
    "            if isinstance(encoder_block_layer, nn.Conv1d):\n",
    "                print(\"nn.Conv1d here\")\n",
    "                conv_layers.append(encoder_block_layer)\n",
    "            elif isinstance(encoder_block_layer, ResidualUnit):\n",
    "                residual_unit_layers = encoder_block_layer.block\n",
    "                print(\"residual unit here\")\n",
    "                for residual_unit_layer in residual_unit_layers:\n",
    "                    if isinstance(residual_unit_layer, nn.Conv1d):\n",
    "                        print(\"nn.Conv1d here\")\n",
    "                        conv_layers.append(residual_unit_layer)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "nn.Conv1d here\n",
      "1 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "2 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "3 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "4 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "encoder block here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "residual unit here\n",
      "nn.Conv1d here\n",
      "nn.Conv1d here\n",
      "5 Snake1d()\n",
      "6 Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "nn.Conv1d here\n",
      "7 Tanh()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       " Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       " Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       " Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       " Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       " Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       " Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       " Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       " Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       " Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       " Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       " Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       " Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       " Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       " Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers = []\n",
    "\n",
    "for idx, layer in enumerate(model.decoder.model):\n",
    "    print(idx, layer)\n",
    "    if isinstance(layer, nn.Conv1d):\n",
    "        print(\"nn.Conv1d here\")\n",
    "        conv_layers.append(layer)\n",
    "    elif isinstance(layer, DecoderBlock):\n",
    "        decoder_block_layers = layer.block\n",
    "        print(\"encoder block here\")\n",
    "        for decoder_block_layer in decoder_block_layers:\n",
    "            if isinstance(decoder_block_layer, nn.Conv1d):\n",
    "                print(\"nn.Conv1d here\")\n",
    "                conv_layers.append(decoder_block_layer)\n",
    "            elif isinstance(decoder_block_layer, ResidualUnit):\n",
    "                residual_unit_layers = decoder_block_layer.block\n",
    "                print(\"residual unit here\")\n",
    "                for residual_unit_layer in residual_unit_layers:\n",
    "                    if isinstance(residual_unit_layer, nn.Conv1d):\n",
    "                        print(\"nn.Conv1d here\")\n",
    "                        conv_layers.append(residual_unit_layer)\n",
    "\n",
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(64, 64, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(64, 64, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(64, 64, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,)),\n",
       "  Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(128, 128, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(128, 128, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(128, 128, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,)),\n",
       "  Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(256, 256, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(256, 256, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(256, 256, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,)),\n",
       "  Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(512, 512, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(512, 512, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(512, 512, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,)),\n",
       "  Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))],\n",
       " [Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,)),\n",
       "  Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(768, 768, kernel_size=(1,), stride=(1,)),\n",
       "  ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,)),\n",
       "  Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(384, 384, kernel_size=(1,), stride=(1,)),\n",
       "  ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,)),\n",
       "  Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(192, 192, kernel_size=(1,), stride=(1,)),\n",
       "  ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,)),\n",
       "  Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)),\n",
       "  Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)),\n",
       "  Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)),\n",
       "  Conv1d(96, 96, kernel_size=(1,), stride=(1,)),\n",
       "  Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_conv_layers(layers, conv_layers):\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            conv_layers.append(layer)\n",
    "        elif hasattr(layer, 'block'):\n",
    "            find_conv_layers(layer.block, conv_layers)\n",
    "\n",
    "encoder_conv_layers = []\n",
    "decoder_conv_layers = []\n",
    "\n",
    "find_conv_layers(model.encoder.block, encoder_conv_layers)\n",
    "find_conv_layers(model.decoder.model, decoder_conv_layers)\n",
    "\n",
    "encoder_conv_layers, decoder_conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sort the channels from important to non-important\n",
    "def get_input_channel_importance_conv1d(weight):\n",
    "    in_channels = weight.shape[1]\n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(in_channels):\n",
    "        channel_weight = weight.detach()[:, i_c]\n",
    "        importance = torch.norm(channel_weight)\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "\n",
    "# function to sort the channels from important to non-important\n",
    "def get_input_channel_importance_convtranspose1d(weight):\n",
    "    in_channels = weight.shape[0]\n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(in_channels):\n",
    "        channel_weight = weight.detach()[i_c, :]\n",
    "        importance = torch.norm(channel_weight)\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_channel_sorting(model):\n",
    "    # model = copy.deepcopy(model)  # do not modify the original model\n",
    "    # fetch all the conv from the model\n",
    "    all_convs = []\n",
    "    find_conv_layers(model.encoder.block, all_convs)\n",
    "    find_conv_layers(model.decoder.model, all_convs)\n",
    "    # iterate through conv layers\n",
    "    for i_conv in range(len(all_convs) - 1):\n",
    "        # each channel sorting index, we need to apply it to:\n",
    "        # - the output dimension of the previous conv\n",
    "        # - the input dimension of the next conv (we compute importance here)\n",
    "        prev_conv = all_convs[i_conv]\n",
    "        next_conv = all_convs[i_conv + 1]\n",
    "        # note that we always compute the importance according to input channels\n",
    "        if (isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            importance = get_input_channel_importance_convtranspose1d(next_conv.weight)\n",
    "        else:\n",
    "            importance = get_input_channel_importance_conv1d(next_conv.weight)\n",
    "        # sorting from large to small\n",
    "        sort_idx = torch.argsort(importance, descending=True)\n",
    "        \n",
    "        # apply to the next conv input\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 0, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 1, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "def get_num_channels_to_keep(channels: int, prune_ratio: float) -> int:\n",
    "    \"\"\"A function to calculate the number of layers to PRESERVE after pruning\n",
    "    Note that preserve_rate = 1. - prune_ratio\n",
    "    \"\"\"\n",
    "    return round((1 - prune_ratio) * channels)\n",
    "\n",
    "@torch.no_grad()\n",
    "def channel_prune(model: nn.Module,\n",
    "                  prune_ratio: Union[List, float]) -> nn.Module:\n",
    "    \"\"\"Apply channel pruning to each of the conv layer in the backbone\n",
    "    Note that for prune_ratio, we can either provide a floating-point number,\n",
    "    indicating that we use a uniform pruning rate for all layers, or a list of\n",
    "    numbers to indicate per-layer pruning rate.\n",
    "    \"\"\"\n",
    "    # sanity check of provided prune_ratio\n",
    "    assert isinstance(prune_ratio, (float, list))\n",
    "    # fetch all the conv from the model\n",
    "    all_convs = []\n",
    "    find_conv_layers(model.encoder.block, all_convs)\n",
    "    find_conv_layers(model.decoder.model, all_convs)\n",
    "    n_conv = len(all_convs)\n",
    "    # note that for the ratios, it affects the previous conv output and next\n",
    "    # conv input, i.e., conv0 - ratio0 - conv1 - ratio1-...\n",
    "    if isinstance(prune_ratio, list):\n",
    "        assert len(prune_ratio) == n_conv - 1\n",
    "    else:  # convert float to list\n",
    "        prune_ratio = [prune_ratio] * (n_conv - 1)\n",
    "\n",
    "    # we prune the convs in the backbone with a uniform ratio\n",
    "    # model = copy.deepcopy(model)  # prevent overwrite\n",
    "    # apply pruning. we naively keep the first k channels\n",
    "    for i_ratio, p_ratio in enumerate(prune_ratio):\n",
    "        prev_conv = all_convs[i_ratio]\n",
    "        next_conv = all_convs[i_ratio + 1]\n",
    "        original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "        n_keep = get_num_channels_to_keep(original_channels, p_ratio)\n",
    "\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:, :n_keep, :])\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:n_keep])\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning\n",
      "Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([64, 1, 7])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([64, 64, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([64, 64, 1])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([64, 64, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([64, 64, 1])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([64, 64, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([64, 64, 1])\n",
      "Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,)) torch.Size([128, 64, 4])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([128, 128, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([128, 128, 1])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([128, 128, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([128, 128, 1])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([128, 128, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([128, 128, 1])\n",
      "Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,)) torch.Size([256, 128, 8])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([256, 256, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([256, 256, 1])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([256, 256, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([256, 256, 1])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([256, 256, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([256, 256, 1])\n",
      "Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([512, 256, 16])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([512, 512, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([512, 512, 1])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([512, 512, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([512, 512, 1])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([512, 512, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([512, 512, 1])\n",
      "Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([1024, 512, 16])\n",
      "Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,)) torch.Size([1024, 1024, 3])\n",
      "Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([1536, 1024, 7])\n",
      "ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([1536, 768, 16])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([768, 768, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([768, 768, 1])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([768, 768, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([768, 768, 1])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([768, 768, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([768, 768, 1])\n",
      "ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([768, 384, 16])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([384, 384, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([384, 384, 1])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([384, 384, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([384, 384, 1])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([384, 384, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([384, 384, 1])\n",
      "ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,)) torch.Size([384, 192, 8])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([192, 192, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([192, 192, 1])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([192, 192, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([192, 192, 1])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([192, 192, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([192, 192, 1])\n",
      "ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,)) torch.Size([192, 96, 4])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([96, 96, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([96, 96, 1])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([96, 96, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([96, 96, 1])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([96, 96, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([96, 96, 1])\n",
      "Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([1, 96, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before pruning\")\n",
    "all_convs = []\n",
    "find_conv_layers(model.encoder.block, all_convs)\n",
    "find_conv_layers(model.decoder.model, all_convs)\n",
    "for conv in all_convs:\n",
    "    print(conv, conv.weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_pruning_ratio = 0.3\n",
    "sorted_model = apply_channel_sorting(model)\n",
    "pruned_model = channel_prune(sorted_model, channel_pruning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning\n",
      "Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([45, 1, 7])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([45, 45, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([45, 45, 1])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([45, 45, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([45, 45, 1])\n",
      "Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([45, 45, 7])\n",
      "Conv1d(64, 64, kernel_size=(1,), stride=(1,)) torch.Size([45, 45, 1])\n",
      "Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,)) torch.Size([90, 45, 4])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([90, 90, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([90, 90, 1])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([90, 90, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([90, 90, 1])\n",
      "Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([90, 90, 7])\n",
      "Conv1d(128, 128, kernel_size=(1,), stride=(1,)) torch.Size([90, 90, 1])\n",
      "Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,)) torch.Size([179, 90, 8])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([179, 179, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([179, 179, 1])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([179, 179, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([179, 179, 1])\n",
      "Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([179, 179, 7])\n",
      "Conv1d(256, 256, kernel_size=(1,), stride=(1,)) torch.Size([179, 179, 1])\n",
      "Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([358, 179, 16])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([358, 358, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([358, 358, 1])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([358, 358, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([358, 358, 1])\n",
      "Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([358, 358, 7])\n",
      "Conv1d(512, 512, kernel_size=(1,), stride=(1,)) torch.Size([358, 358, 1])\n",
      "Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([717, 358, 16])\n",
      "Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,)) torch.Size([717, 717, 3])\n",
      "Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([1075, 717, 7])\n",
      "ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([1075, 538, 16])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([538, 538, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([538, 538, 1])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([538, 538, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([538, 538, 1])\n",
      "Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([538, 538, 7])\n",
      "Conv1d(768, 768, kernel_size=(1,), stride=(1,)) torch.Size([538, 538, 1])\n",
      "ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,)) torch.Size([538, 269, 16])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([269, 269, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([269, 269, 1])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([269, 269, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([269, 269, 1])\n",
      "Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([269, 269, 7])\n",
      "Conv1d(384, 384, kernel_size=(1,), stride=(1,)) torch.Size([269, 269, 1])\n",
      "ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,)) torch.Size([269, 134, 8])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([134, 134, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([134, 134, 1])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([134, 134, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([134, 134, 1])\n",
      "Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([134, 134, 7])\n",
      "Conv1d(192, 192, kernel_size=(1,), stride=(1,)) torch.Size([134, 134, 1])\n",
      "ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,)) torch.Size([134, 67, 4])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([67, 67, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([67, 67, 1])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) torch.Size([67, 67, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([67, 67, 1])\n",
      "Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) torch.Size([67, 67, 7])\n",
      "Conv1d(96, 96, kernel_size=(1,), stride=(1,)) torch.Size([67, 67, 1])\n",
      "Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,)) torch.Size([1, 67, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"After pruning\")\n",
    "all_convs = []\n",
    "find_conv_layers(model.encoder.block, all_convs)\n",
    "find_conv_layers(model.decoder.model, all_convs)\n",
    "for conv in all_convs:\n",
    "    print(conv, conv.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress and Decompress + Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0102), tensor(2.0919), tensor(0.0179))"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dac.utils import load_model\n",
    "from dac import DACFile\n",
    "from train import losses\n",
    "from dataclasses import dataclass\n",
    "\n",
    "ref_generator = load_model(\n",
    "    model_type=\"44khz\",\n",
    "    model_bitrate=\"8kbps\",\n",
    "    tag=\"latest\",\n",
    "    load_path=model_path,\n",
    ")\n",
    "\n",
    "audio_file_path = \"../samples/UrbanSound8K 7383-3-0-0.wav\"\n",
    "\n",
    "signal = AudioSignal(audio_file_path)\n",
    "\n",
    "artifact = ref_generator.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "recons = ref_generator.decompress(artifact, verbose=False)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "x = signal.clone().resample(44100)\n",
    "y = recons.clone().resample(44100)\n",
    "mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DACFile(codes=tensor([[[568, 698, 481,  ..., 205, 283, 283],\n",
       "          [778, 245, 331,  ..., 678, 245, 538],\n",
       "          [708, 737, 182,  ...,  20, 624, 379],\n",
       "          ...,\n",
       "          [500, 263, 801,  ..., 120, 506, 687],\n",
       "          [860, 788, 943,  ..., 675, 997, 802],\n",
       "          [628, 367, 112,  ..., 366, 349, 597]],\n",
       " \n",
       "         [[568, 698, 618,  ..., 315, 283, 315],\n",
       "          [778, 245, 914,  ..., 217,   7, 898],\n",
       "          [566,  10, 879,  ..., 333, 624, 702],\n",
       "          ...,\n",
       "          [545,  63, 847,  ..., 972, 147, 668],\n",
       "          [614, 579, 746,  ..., 613, 153,  98],\n",
       "          [628, 827, 799,  ..., 929, 663, 870]]]), chunk_length=345, original_length=176400, input_db=tensor([-18.7919]), channels=2, sample_rate=44100, padding=True, dac_version='1.0.0'),\n",
       " <audiotools.core.audio_signal.AudioSignal at 0x204c9e64290>)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact, recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<audiotools.core.audio_signal.AudioSignal at 0x204c76c3bd0>,\n",
       " <audiotools.core.audio_signal.AudioSignal at 0x204c79aead0>)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0102), tensor(2.0919), tensor(0.0179))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_pruning_ratio = 0.3\n",
    "sorted_model = apply_channel_sorting(ref_generator)\n",
    "pruned_model = channel_prune(sorted_model, channel_pruning_ratio)\n",
    "\n",
    "artifact = pruned_model.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "recons = pruned_model.decompress(artifact, verbose=False)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "x = signal.clone().resample(44100)\n",
    "y = recons.clone().resample(44100)\n",
    "mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DACFile(codes=tensor([[[568, 698, 481,  ..., 205, 283, 283],\n",
       "          [778, 245, 331,  ..., 678, 245, 538],\n",
       "          [708, 737, 182,  ...,  20, 624, 379],\n",
       "          ...,\n",
       "          [500, 263, 801,  ..., 120, 506, 687],\n",
       "          [860, 788, 943,  ..., 675, 997, 802],\n",
       "          [628, 367, 112,  ..., 366, 349, 597]],\n",
       " \n",
       "         [[568, 698, 618,  ..., 315, 283, 315],\n",
       "          [778, 245, 914,  ..., 217,   7, 898],\n",
       "          [566,  10, 879,  ..., 333, 624, 702],\n",
       "          ...,\n",
       "          [545,  63, 847,  ..., 972, 147, 668],\n",
       "          [614, 579, 746,  ..., 613, 153,  98],\n",
       "          [628, 827, 799,  ..., 929, 663, 870]]]), chunk_length=345, original_length=176400, input_db=tensor([-18.7919]), channels=2, sample_rate=44100, padding=True, dac_version='1.0.0'),\n",
       " <audiotools.core.audio_signal.AudioSignal at 0x204ca04add0>)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact, recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<audiotools.core.audio_signal.AudioSignal at 0x204c774c0d0>,\n",
       " <audiotools.core.audio_signal.AudioSignal at 0x204ca04a350>)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def uniform_sparsity_testing(model_path, audio_file_path, channel_pruning_ratios):\n",
    "    mel_losses = []\n",
    "    stft_losses = []\n",
    "    waveform_losses = []\n",
    "\n",
    "    waveform_loss = losses.L1Loss()\n",
    "    stft_loss = losses.MultiScaleSTFTLoss()\n",
    "    mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "    signal = AudioSignal(audio_file_path)\n",
    "\n",
    "    for channel_pruning_ratio in tqdm(channel_pruning_ratios):\n",
    "        model = dac.DAC.load(model_path)\n",
    "\n",
    "        sorted_model = apply_channel_sorting(model)\n",
    "        pruned_model = channel_prune(sorted_model, channel_pruning_ratio)\n",
    "        # all_convs = []\n",
    "        # find_conv_layers(pruned_model.encoder.block, all_convs)\n",
    "        # find_conv_layers(pruned_model.decoder.model, all_convs)\n",
    "        # for conv in all_convs:\n",
    "        #     print(conv, conv.weight.shape)\n",
    "        # print(all_convs[0].weight)\n",
    "\n",
    "        artifact = pruned_model.compress(signal.clone(), win_duration=5.0, verbose=False)\n",
    "        recons = pruned_model.decompress(artifact, verbose=False)\n",
    "\n",
    "        x = signal.clone().resample(44100)\n",
    "        y = recons.clone().resample(44100)\n",
    "\n",
    "        mel_losses.append(mel_loss(x, y))\n",
    "        stft_losses.append(stft_loss(x, y))\n",
    "        waveform_losses.append(waveform_loss(x, y))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(channel_pruning_ratios, mel_losses, label='Mel Loss')\n",
    "    plt.plot(channel_pruning_ratios, stft_losses, label='STFT Loss')\n",
    "    plt.plot(channel_pruning_ratios, waveform_losses, label='Waveform Loss')\n",
    "\n",
    "    plt.xlabel('Channel Pruning Ratio')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.title('Losses for Different Channel Pruning Ratios')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:10<00:00,  8.84s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_file_path = \"../samples/UrbanSound8K 7383-3-0-0.wav\"\n",
    "channel_pruning_ratios = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "uniform_sparsity_testing(model_path, audio_file_path, channel_pruning_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
