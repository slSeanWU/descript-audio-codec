{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dac\n",
    "from dac.model.dac import EncoderBlock, DecoderBlock, ResidualUnit\n",
    "from dac.nn.layers import Snake1d\n",
    "from audiotools import AudioSignal\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\audiotools\\ml\\layers\\base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\")\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAC(\n",
       "  (encoder): Encoder(\n",
       "    (block): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): Snake1d()\n",
       "          (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    )\n",
       "  )\n",
       "  (quantizer): ResidualVectorQuantize(\n",
       "    (quantizers): ModuleList(\n",
       "      (0-8): 9 x VectorQuantize(\n",
       "        (in_proj): Conv1d(1024, 8, kernel_size=(1,), stride=(1,))\n",
       "        (out_proj): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (codebook): Embedding(1024, 8)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (model): Sequential(\n",
       "      (0): Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (1): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Snake1d()\n",
       "          (1): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "          (2): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (4): ResidualUnit(\n",
       "            (block): Sequential(\n",
       "              (0): Snake1d()\n",
       "              (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "              (2): Snake1d()\n",
       "              (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Snake1d()\n",
       "      (6): Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "1 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "  )\n",
      ")\n",
      "2 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  )\n",
      ")\n",
      "3 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "  )\n",
      ")\n",
      "4 EncoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): Snake1d()\n",
      "    (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "  )\n",
      ")\n",
      "5 Snake1d()\n",
      "6 Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n"
     ]
    }
   ],
   "source": [
    "conv_layers = []\n",
    "\n",
    "for idx, layer in enumerate(model.encoder.block):\n",
    "    print(idx, layer)\n",
    "    if isinstance(layer, nn.Conv1d):\n",
    "        # print(\"nn.Conv1d here\")\n",
    "        conv_layers.append(layer)\n",
    "    elif isinstance(layer, EncoderBlock):\n",
    "        encoder_block_layers = layer.block\n",
    "        # print(\"encoder block here\")\n",
    "        for encoder_block_layer in encoder_block_layers:\n",
    "            if isinstance(encoder_block_layer, nn.Conv1d):\n",
    "                # print(\"nn.Conv1d here\")\n",
    "                conv_layers.append(encoder_block_layer)\n",
    "            elif isinstance(encoder_block_layer, ResidualUnit):\n",
    "                residual_unit_layers = encoder_block_layer.block\n",
    "                # print(\"residual unit here\")\n",
    "                # print(residual_unit_layers[0])\n",
    "                # print(residual_unit_layers[1])\n",
    "                # print(residual_unit_layers[2])\n",
    "                # print(residual_unit_layers[3])\n",
    "                \n",
    "                for residual_unit_layer in residual_unit_layers:\n",
    "                    if isinstance(residual_unit_layer, nn.Conv1d):\n",
    "                        # print(\"nn.Conv1d here\")\n",
    "                        conv_layers.append(residual_unit_layer)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "1 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "3 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "4 DecoderBlock(\n",
      "  (block): Sequential(\n",
      "    (0): Snake1d()\n",
      "    (1): ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (2): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualUnit(\n",
      "      (block): Sequential(\n",
      "        (0): Snake1d()\n",
      "        (1): Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
      "        (2): Snake1d()\n",
      "        (3): Conv1d(96, 96, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "5 Snake1d()\n",
      "6 Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "7 Tanh()\n"
     ]
    }
   ],
   "source": [
    "conv_layers = []\n",
    "\n",
    "for idx, layer in enumerate(model.decoder.model):\n",
    "    print(idx, layer)\n",
    "    if isinstance(layer, nn.Conv1d):\n",
    "        # print(\"nn.Conv1d here\")\n",
    "        conv_layers.append(layer)\n",
    "    elif isinstance(layer, DecoderBlock):\n",
    "        decoder_block_layers = layer.block\n",
    "        # print(\"encoder block here\")\n",
    "        for decoder_block_layer in decoder_block_layers:\n",
    "            if isinstance(decoder_block_layer, nn.Conv1d):\n",
    "                # print(\"nn.Conv1d here\")\n",
    "                conv_layers.append(decoder_block_layer)\n",
    "            elif isinstance(decoder_block_layer, ResidualUnit):\n",
    "                residual_unit_layers = decoder_block_layer.block\n",
    "                # print(\"residual unit here\")\n",
    "                for residual_unit_layer in residual_unit_layers:\n",
    "                    if isinstance(residual_unit_layer, nn.Conv1d):\n",
    "                        # print(\"nn.Conv1d here\")\n",
    "                        conv_layers.append(residual_unit_layer)\n",
    "\n",
    "# conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wn(layers):\n",
    "    for idx, layer in enumerate(layers):\n",
    "        if isinstance(layer, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            wn_removed_layer = nn.utils.remove_weight_norm(layer)\n",
    "            layers[idx] = wn_removed_layer\n",
    "        elif hasattr(layer, 'block'):\n",
    "            remove_wn(layer.block)\n",
    "\n",
    "def find_conv_layers(layers, conv_layers):\n",
    "    for idx, layer in enumerate(layers):\n",
    "        if isinstance(layer, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            conv_layers.append(layer)\n",
    "        elif hasattr(layer, 'block'):\n",
    "            find_conv_layers(layer.block, conv_layers)\n",
    "\n",
    "def find_layers(layers, conv_layers, snake_layers):\n",
    "    for idx, layer in enumerate(layers):\n",
    "        if isinstance(layer, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "            # print(idx, layer, layer.weight.shape, layer.bias.shape)\n",
    "            conv_layers.append(layer)\n",
    "            if len(conv_layers) != len(snake_layers):\n",
    "                snake_layers.append(None)\n",
    "        elif isinstance(layer, Snake1d):\n",
    "            snake_layers.append(layer)\n",
    "        elif hasattr(layer, 'block'):\n",
    "            find_layers(layer.block, conv_layers, snake_layers)\n",
    "\n",
    "# [\n",
    "#     [(unit1.snake1, 1), (unit1.block.conv1, 1), (unit1.block.conv2, 0), (unit2.snake1.1), ...]  # channels of activation on the residual path, they are dependent\n",
    "#     [(unit1.block.conv1, 0), (unit1.block.snake2, 1), (unit1.block.conv2, 1)], # channels of the intermediate activation in the block of unit 1, they are dependent\n",
    "#     []\n",
    "    \n",
    "#     ]\n",
    "\n",
    "remove_wn(model.encoder.block)\n",
    "remove_wn(model.decoder.model)\n",
    "\n",
    "encoder_conv_layers = []\n",
    "encoder_snake_layers = []\n",
    "\n",
    "decoder_conv_layers = []\n",
    "decoder_snake_layers = []\n",
    "\n",
    "find_layers(model.encoder.block, encoder_conv_layers, encoder_snake_layers)\n",
    "find_layers(model.decoder.model, decoder_conv_layers, decoder_snake_layers)\n",
    "\n",
    "# encoder_conv_layers, decoder_conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sort the channels from important to non-important\n",
    "def get_input_channel_importance_conv1d(weight):\n",
    "    in_channels = weight.shape[1]\n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(in_channels):\n",
    "        channel_weight = weight.detach()[:, i_c]\n",
    "        importance = torch.norm(channel_weight)\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "\n",
    "# function to sort the channels from important to non-important\n",
    "def get_input_channel_importance_convtranspose1d(weight):\n",
    "    in_channels = weight.shape[0]\n",
    "    importances = []\n",
    "    # compute the importance for each input channel\n",
    "    for i_c in range(in_channels):\n",
    "        channel_weight = weight.detach()[i_c, :]\n",
    "        importance = torch.norm(channel_weight)\n",
    "        importances.append(importance.view(1))\n",
    "    return torch.cat(importances)\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_channel_sorting(model):\n",
    "    # model = copy.deepcopy(model)  # do not modify the original model\n",
    "    # fetch all the conv from the model\n",
    "    all_convs = []\n",
    "    all_snakes = []\n",
    "    find_layers(model.encoder.block, all_convs, all_snakes)\n",
    "    find_layers(model.decoder.model, all_convs, all_snakes)\n",
    "    # iterate through conv layers\n",
    "    for i_conv in range(len(all_convs) - 1):\n",
    "        # each channel sorting index, we need to apply it to:\n",
    "        # - the output dimension of the previous conv\n",
    "        # - the input dimension of the next conv (we compute importance here)\n",
    "        prev_conv = all_convs[i_conv]\n",
    "        next_conv = all_convs[i_conv + 1]\n",
    "        next_snake = all_snakes[i_conv + 1]\n",
    "        # note that we always compute the importance according to input channels\n",
    "        if (isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            importance = get_input_channel_importance_convtranspose1d(next_conv.weight)\n",
    "        else:\n",
    "            importance = get_input_channel_importance_conv1d(next_conv.weight)\n",
    "        # sorting from large to small\n",
    "        sort_idx = torch.argsort(importance, descending=True)\n",
    "        \n",
    "        # apply to the next conv input\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 0, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 1, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "\n",
    "        prev_conv.bias.copy_(torch.index_select(prev_conv.bias.detach(), 0, sort_idx))\n",
    "        \n",
    "        if next_snake:\n",
    "            next_snake.alpha.data = torch.index_select(next_snake.alpha.data, 1, sort_idx)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "def get_num_channels_to_keep(channels: int, prune_ratio: float) -> int:\n",
    "    \"\"\"A function to calculate the number of layers to PRESERVE after pruning\n",
    "    Note that preserve_rate = 1. - prune_ratio\n",
    "    \"\"\"\n",
    "    return round((1 - prune_ratio) * channels)\n",
    "\n",
    "@torch.no_grad()\n",
    "def channel_prune(model: nn.Module,\n",
    "                  prune_ratio: Union[List, float]) -> nn.Module:\n",
    "    \"\"\"Apply channel pruning to each of the conv layer in the backbone\n",
    "    Note that for prune_ratio, we can either provide a floating-point number,\n",
    "    indicating that we use a uniform pruning rate for all layers, or a list of\n",
    "    numbers to indicate per-layer pruning rate.\n",
    "    \"\"\"\n",
    "    # sanity check of provided prune_ratio\n",
    "    assert isinstance(prune_ratio, (float, list))\n",
    "    # fetch all the conv from the model\n",
    "    all_convs = []\n",
    "    all_snakes = []\n",
    "    find_layers(model.encoder.block, all_convs, all_snakes)\n",
    "    find_layers(model.decoder.model, all_convs, all_snakes)\n",
    "    n_conv = len(all_convs)\n",
    "    # note that for the ratios, it affects the previous conv output and next\n",
    "    # conv input, i.e., conv0 - ratio0 - conv1 - ratio1-...\n",
    "    if isinstance(prune_ratio, list):\n",
    "        assert len(prune_ratio) == n_conv - 1\n",
    "    else:  # convert float to list\n",
    "        prune_ratio = [prune_ratio] * (n_conv - 1)\n",
    "\n",
    "    # we prune the convs in the backbone with a uniform ratio\n",
    "    # model = copy.deepcopy(model)  # prevent overwrite\n",
    "    # apply pruning. we naively keep the first k channels\n",
    "    for i_ratio, p_ratio in enumerate(prune_ratio):\n",
    "        prev_conv = all_convs[i_ratio]\n",
    "        next_conv = all_convs[i_ratio + 1]\n",
    "        next_snake = all_snakes[i_ratio + 1]\n",
    "        original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "        n_keep = get_num_channels_to_keep(original_channels, p_ratio)\n",
    "\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:, :n_keep, :])\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:n_keep])\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.set_(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "            next_conv.weight.set_(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "        prev_conv.bias.set_(prev_conv.bias.detach()[:n_keep])\n",
    "\n",
    "        if next_snake:\n",
    "            next_snake.alpha.data = next_snake.alpha.data[:, :n_keep, :]\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort idx tensor([1, 4, 2, 0, 3])\n",
      "premutation tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 1, 2, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 1, 2, 4, 3])\n",
      "tensor([0, 1, 2, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 1, 3, 2, 4])\n",
      "tensor([0, 1, 3, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 1, 3, 4, 2])\n",
      "tensor([0, 1, 3, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 1, 4, 2, 3])\n",
      "tensor([0, 1, 4, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 1, 4, 3, 2])\n",
      "tensor([0, 1, 4, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 1, 3, 4])\n",
      "tensor([0, 2, 1, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 1, 4, 3])\n",
      "tensor([0, 2, 1, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 3, 1, 4])\n",
      "tensor([0, 2, 3, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 3, 4, 1])\n",
      "tensor([0, 2, 3, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 4, 1, 3])\n",
      "tensor([0, 2, 4, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 2, 4, 3, 1])\n",
      "tensor([0, 2, 4, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 1, 2, 4])\n",
      "tensor([0, 3, 1, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 1, 4, 2])\n",
      "tensor([0, 3, 1, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 2, 1, 4])\n",
      "tensor([0, 3, 2, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 2, 4, 1])\n",
      "tensor([0, 3, 2, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 4, 1, 2])\n",
      "tensor([0, 3, 4, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 3, 4, 2, 1])\n",
      "tensor([0, 3, 4, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 1, 2, 3])\n",
      "tensor([0, 4, 1, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 1, 3, 2])\n",
      "tensor([0, 4, 1, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 2, 1, 3])\n",
      "tensor([0, 4, 2, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 2, 3, 1])\n",
      "tensor([0, 4, 2, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 3, 1, 2])\n",
      "tensor([0, 4, 3, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([0, 4, 3, 2, 1])\n",
      "tensor([0, 4, 3, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 2, 3, 4])\n",
      "tensor([1, 0, 2, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 2, 4, 3])\n",
      "tensor([1, 0, 2, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 3, 2, 4])\n",
      "tensor([1, 0, 3, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 3, 4, 2])\n",
      "tensor([1, 0, 3, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 4, 2, 3])\n",
      "tensor([1, 0, 4, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 0, 4, 3, 2])\n",
      "tensor([1, 0, 4, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 0, 3, 4])\n",
      "tensor([1, 2, 0, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 0, 4, 3])\n",
      "tensor([1, 2, 0, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 3, 0, 4])\n",
      "tensor([1, 2, 3, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 3, 4, 0])\n",
      "tensor([1, 2, 3, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 4, 0, 3])\n",
      "tensor([1, 2, 4, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 2, 4, 3, 0])\n",
      "tensor([1, 2, 4, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 0, 2, 4])\n",
      "tensor([1, 3, 0, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 0, 4, 2])\n",
      "tensor([1, 3, 0, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 2, 0, 4])\n",
      "tensor([1, 3, 2, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 2, 4, 0])\n",
      "tensor([1, 3, 2, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 4, 0, 2])\n",
      "tensor([1, 3, 4, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 3, 4, 2, 0])\n",
      "tensor([1, 3, 4, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 0, 2, 3])\n",
      "tensor([1, 4, 0, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 0, 3, 2])\n",
      "tensor([1, 4, 0, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 2, 0, 3])\n",
      "tensor([1, 4, 2, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 2, 3, 0])\n",
      "tensor([1, 4, 2, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 3, 0, 2])\n",
      "tensor([1, 4, 3, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([1, 4, 3, 2, 0])\n",
      "tensor([1, 4, 3, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 1, 3, 4])\n",
      "tensor([2, 0, 1, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 1, 4, 3])\n",
      "tensor([2, 0, 1, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 3, 1, 4])\n",
      "tensor([2, 0, 3, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 3, 4, 1])\n",
      "tensor([2, 0, 3, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 4, 1, 3])\n",
      "tensor([2, 0, 4, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 0, 4, 3, 1])\n",
      "tensor([2, 0, 4, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 0, 3, 4])\n",
      "tensor([2, 1, 0, 3, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 0, 4, 3])\n",
      "tensor([2, 1, 0, 4, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 3, 0, 4])\n",
      "tensor([2, 1, 3, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 3, 4, 0])\n",
      "tensor([2, 1, 3, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 4, 0, 3])\n",
      "tensor([2, 1, 4, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 1, 4, 3, 0])\n",
      "tensor([2, 1, 4, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 0, 1, 4])\n",
      "tensor([2, 3, 0, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 0, 4, 1])\n",
      "tensor([2, 3, 0, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 1, 0, 4])\n",
      "tensor([2, 3, 1, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 1, 4, 0])\n",
      "tensor([2, 3, 1, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 4, 0, 1])\n",
      "tensor([2, 3, 4, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 3, 4, 1, 0])\n",
      "tensor([2, 3, 4, 1, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 0, 1, 3])\n",
      "tensor([2, 4, 0, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 0, 3, 1])\n",
      "tensor([2, 4, 0, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 1, 0, 3])\n",
      "tensor([2, 4, 1, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 1, 3, 0])\n",
      "tensor([2, 4, 1, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 3, 0, 1])\n",
      "tensor([2, 4, 3, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([2, 4, 3, 1, 0])\n",
      "tensor([2, 4, 3, 1, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 1, 2, 4])\n",
      "tensor([3, 0, 1, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 1, 4, 2])\n",
      "tensor([3, 0, 1, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 2, 1, 4])\n",
      "tensor([3, 0, 2, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 2, 4, 1])\n",
      "tensor([3, 0, 2, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 4, 1, 2])\n",
      "tensor([3, 0, 4, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 0, 4, 2, 1])\n",
      "tensor([3, 0, 4, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 0, 2, 4])\n",
      "tensor([3, 1, 0, 2, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 0, 4, 2])\n",
      "tensor([3, 1, 0, 4, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 2, 0, 4])\n",
      "tensor([3, 1, 2, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 2, 4, 0])\n",
      "tensor([3, 1, 2, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 4, 0, 2])\n",
      "tensor([3, 1, 4, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 1, 4, 2, 0])\n",
      "tensor([3, 1, 4, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 0, 1, 4])\n",
      "tensor([3, 2, 0, 1, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 0, 4, 1])\n",
      "tensor([3, 2, 0, 4, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 1, 0, 4])\n",
      "tensor([3, 2, 1, 0, 4]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 1, 4, 0])\n",
      "tensor([3, 2, 1, 4, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 4, 0, 1])\n",
      "tensor([3, 2, 4, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 2, 4, 1, 0])\n",
      "tensor([3, 2, 4, 1, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 0, 1, 2])\n",
      "tensor([3, 4, 0, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 0, 2, 1])\n",
      "tensor([3, 4, 0, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 1, 0, 2])\n",
      "tensor([3, 4, 1, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 1, 2, 0])\n",
      "tensor([3, 4, 1, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 2, 0, 1])\n",
      "tensor([3, 4, 2, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([3, 4, 2, 1, 0])\n",
      "tensor([3, 4, 2, 1, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 1, 2, 3])\n",
      "tensor([4, 0, 1, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 1, 3, 2])\n",
      "tensor([4, 0, 1, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 2, 1, 3])\n",
      "tensor([4, 0, 2, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 2, 3, 1])\n",
      "tensor([4, 0, 2, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 3, 1, 2])\n",
      "tensor([4, 0, 3, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 0, 3, 2, 1])\n",
      "tensor([4, 0, 3, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 0, 2, 3])\n",
      "tensor([4, 1, 0, 2, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 0, 3, 2])\n",
      "tensor([4, 1, 0, 3, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 2, 0, 3])\n",
      "tensor([4, 1, 2, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 2, 3, 0])\n",
      "tensor([4, 1, 2, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 3, 0, 2])\n",
      "tensor([4, 1, 3, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 1, 3, 2, 0])\n",
      "tensor([4, 1, 3, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 0, 1, 3])\n",
      "tensor([4, 2, 0, 1, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 0, 3, 1])\n",
      "tensor([4, 2, 0, 3, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 1, 0, 3])\n",
      "tensor([4, 2, 1, 0, 3]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 1, 3, 0])\n",
      "tensor([4, 2, 1, 3, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 3, 0, 1])\n",
      "tensor([4, 2, 3, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 2, 3, 1, 0])\n",
      "tensor([4, 2, 3, 1, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 0, 1, 2])\n",
      "tensor([4, 3, 0, 1, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 0, 2, 1])\n",
      "tensor([4, 3, 0, 2, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 1, 0, 2])\n",
      "tensor([4, 3, 1, 0, 2]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 1, 2, 0])\n",
      "tensor([4, 3, 1, 2, 0]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 2, 0, 1])\n",
      "tensor([4, 3, 2, 0, 1]) The final outputs are the same after sorting.\n",
      "premutation tensor([4, 3, 2, 1, 0])\n",
      "tensor([4, 3, 2, 1, 0]) The final outputs are the same after sorting.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "in_channels = 3\n",
    "oc = 5\n",
    "\n",
    "# Mini test code with Conv1d -> Snake1d -> Conv1d\n",
    "input_tensor = torch.randn(1, 5, 5)\n",
    "\n",
    "conv1d_1 = nn.Conv1d(in_channels=5, out_channels=oc, kernel_size=1, padding=1, bias=False)\n",
    "\n",
    "snake1d = Snake1d(channels=oc)\n",
    "original_snake_weights = torch.rand(1, oc, 1) \n",
    "snake1d.alpha.data = original_snake_weights # Random alpha values for each channel\n",
    "# print(type(snake1d.alpha), snake1d.alpha)\n",
    "\n",
    "conv1d_2 = nn.Conv1d(in_channels=oc, out_channels=1, kernel_size=1, padding=1, bias=False)\n",
    "\n",
    "original_conv1d_output = conv1d_1(input_tensor)\n",
    "original_snake_output = snake1d(original_conv1d_output)\n",
    "original_output = conv1d_2(original_snake_output)\n",
    "\n",
    "importance = get_input_channel_importance_conv1d(conv1d_2.weight)\n",
    "sort_idx = torch.argsort(importance, descending=True)\n",
    "print(\"sort idx\", sort_idx)\n",
    "\n",
    "permutations = list(itertools.permutations(list(range(len(importance)))))\n",
    "\n",
    "orig_weights = [conv1d_1.weight.data, conv1d_2.weight.data, snake1d.alpha.data]\n",
    "\n",
    "for perm in permutations:\n",
    "    perm = torch.tensor(perm)\n",
    "    print(\"premutation\", perm)\n",
    "\n",
    "    conv1d_1.weight = nn.Parameter(torch.index_select(orig_weights[0], 0, perm))\n",
    "    conv1d_2.weight = nn.Parameter(torch.index_select(orig_weights[1], 1, perm))\n",
    "    snake1d.alpha = nn.Parameter(torch.index_select(orig_weights[2], 1, perm))\n",
    "    # print(snake1d.alpha)\n",
    "    # print(conv1d_1.weight)\n",
    "    # print(conv1d_2.weight)\n",
    "\n",
    "    sorted_conv1d_output = conv1d_1(input_tensor)\n",
    "    sorted_snake_output = snake1d(sorted_conv1d_output)\n",
    "    # if torch.allclose(original_output, sorted_output, atol=1e-6):\n",
    "    #     print(\"\\nThe outputs are the same after sorting.\")\n",
    "    #     print(sort_idx, perm)\n",
    "    sorted_output = conv1d_2(sorted_snake_output)\n",
    "\n",
    "    # print(\"Original Output:\")\n",
    "    # print(original_output)\n",
    "    # print(\"\\nSorted Output:\")\n",
    "    # print(sorted_output)\n",
    "\n",
    "    # if torch.allclose(original_conv1d_output, sorted_conv1d_output, atol=1e-4):\n",
    "    #     print(perm, \"The conv1d outputs are the same after sorting.\")\n",
    "    #     # print(sort_idx, perm)\n",
    "    # else:\n",
    "    #     print(perm, \"The conv1d outputs are not the same after sorting.\")\n",
    "\n",
    "    # if torch.allclose(original_snake_output, sorted_snake_output, atol=1e-4):\n",
    "    #     print(\"\\nThe snake outputs are the same after sorting.\")\n",
    "    #     # print(sort_idx, perm)\n",
    "\n",
    "    if torch.allclose(original_output, sorted_output, atol=1e-4):\n",
    "        print(perm, \"The final outputs are the same after sorting.\")\n",
    "        # print(sort_idx, perm)\n",
    "    else:\n",
    "        print(perm, \"The outputs are different after sorting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning\n",
      "layer: Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([64, 1, 7]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([64, 64, 7]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([64, 64, 1]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([64, 64, 7]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([64, 64, 1]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([64, 64, 7]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([64, 64, 1]) \tbias shape: torch.Size([64])\n",
      "layer: Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,)) \tweight shape: torch.Size([128, 64, 4]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([128, 128, 7]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([128, 128, 1]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([128, 128, 7]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([128, 128, 1]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([128, 128, 7]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([128, 128, 1]) \tbias shape: torch.Size([128])\n",
      "layer: Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,)) \tweight shape: torch.Size([256, 128, 8]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([256, 256, 7]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([256, 256, 1]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([256, 256, 7]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([256, 256, 1]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([256, 256, 7]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([256, 256, 1]) \tbias shape: torch.Size([256])\n",
      "layer: Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([512, 256, 16]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([512, 512, 7]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([512, 512, 1]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([512, 512, 7]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([512, 512, 1]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([512, 512, 7]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([512, 512, 1]) \tbias shape: torch.Size([512])\n",
      "layer: Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([1024, 512, 16]) \tbias shape: torch.Size([1024])\n",
      "layer: Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,)) \tweight shape: torch.Size([1024, 1024, 3]) \tbias shape: torch.Size([1024])\n",
      "layer: Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([1536, 1024, 7]) \tbias shape: torch.Size([1536])\n",
      "layer: ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([1536, 768, 16]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([768, 768, 7]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([768, 768, 1]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([768, 768, 7]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([768, 768, 1]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([768, 768, 7]) \tbias shape: torch.Size([768])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([768, 768, 1]) \tbias shape: torch.Size([768])\n",
      "layer: ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([768, 384, 16]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([384, 384, 7]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([384, 384, 1]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([384, 384, 7]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([384, 384, 1]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([384, 384, 7]) \tbias shape: torch.Size([384])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([384, 384, 1]) \tbias shape: torch.Size([384])\n",
      "layer: ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,)) \tweight shape: torch.Size([384, 192, 8]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([192, 192, 7]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([192, 192, 1]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([192, 192, 7]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([192, 192, 1]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([192, 192, 7]) \tbias shape: torch.Size([192])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([192, 192, 1]) \tbias shape: torch.Size([192])\n",
      "layer: ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,)) \tweight shape: torch.Size([192, 96, 4]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([96, 96, 7]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([96, 96, 1]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([96, 96, 7]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([96, 96, 1]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([96, 96, 7]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([96, 96, 1]) \tbias shape: torch.Size([96])\n",
      "layer: Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([1, 96, 7]) \tbias shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "model = dac.DAC.load(model_path)\n",
    "\n",
    "print(\"Before pruning\")\n",
    "all_convs = []\n",
    "find_conv_layers(model.encoder.block, all_convs)\n",
    "find_conv_layers(model.decoder.model, all_convs)\n",
    "for conv in all_convs:\n",
    "    print(\"layer:\", conv, \"\\tweight shape:\", conv.weight.shape, \"\\tbias shape:\", conv.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_pruning_ratio = 0.3\n",
    "sorted_model = apply_channel_sorting(model)\n",
    "pruned_model = channel_prune(sorted_model, channel_pruning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning\n",
      "layer: Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([45, 1, 7]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([45, 45, 7]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([45, 45, 1]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([45, 45, 7]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([45, 45, 1]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([45, 45, 7]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 64, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([45, 45, 1]) \tbias shape: torch.Size([45])\n",
      "layer: Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,)) \tweight shape: torch.Size([90, 45, 4]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([90, 90, 7]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([90, 90, 1]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([90, 90, 7]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([90, 90, 1]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([90, 90, 7]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 128, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([90, 90, 1]) \tbias shape: torch.Size([90])\n",
      "layer: Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,)) \tweight shape: torch.Size([179, 90, 8]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([179, 179, 7]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([179, 179, 1]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([179, 179, 7]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([179, 179, 1]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([179, 179, 7]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 256, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([179, 179, 1]) \tbias shape: torch.Size([179])\n",
      "layer: Conv1d(256, 512, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([358, 179, 16]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([358, 358, 7]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([358, 358, 1]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([358, 358, 7]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([358, 358, 1]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([358, 358, 7]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 512, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([358, 358, 1]) \tbias shape: torch.Size([358])\n",
      "layer: Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([717, 358, 16]) \tbias shape: torch.Size([717])\n",
      "layer: Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,)) \tweight shape: torch.Size([717, 717, 3]) \tbias shape: torch.Size([717])\n",
      "layer: Conv1d(1024, 1536, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([1075, 717, 7]) \tbias shape: torch.Size([1075])\n",
      "layer: ConvTranspose1d(1536, 768, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([1075, 538, 16]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([538, 538, 7]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([538, 538, 1]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([538, 538, 7]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([538, 538, 1]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([538, 538, 7]) \tbias shape: torch.Size([538])\n",
      "layer: Conv1d(768, 768, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([538, 538, 1]) \tbias shape: torch.Size([538])\n",
      "layer: ConvTranspose1d(768, 384, kernel_size=(16,), stride=(8,), padding=(4,)) \tweight shape: torch.Size([538, 269, 16]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([269, 269, 7]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([269, 269, 1]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([269, 269, 7]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([269, 269, 1]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([269, 269, 7]) \tbias shape: torch.Size([269])\n",
      "layer: Conv1d(384, 384, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([269, 269, 1]) \tbias shape: torch.Size([269])\n",
      "layer: ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,), padding=(2,)) \tweight shape: torch.Size([269, 134, 8]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([134, 134, 7]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([134, 134, 1]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([134, 134, 7]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([134, 134, 1]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([134, 134, 7]) \tbias shape: torch.Size([134])\n",
      "layer: Conv1d(192, 192, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([134, 134, 1]) \tbias shape: torch.Size([134])\n",
      "layer: ConvTranspose1d(192, 96, kernel_size=(4,), stride=(2,), padding=(1,)) \tweight shape: torch.Size([134, 67, 4]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([67, 67, 7]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([67, 67, 1]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)) \tweight shape: torch.Size([67, 67, 7]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([67, 67, 1]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,)) \tweight shape: torch.Size([67, 67, 7]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 96, kernel_size=(1,), stride=(1,)) \tweight shape: torch.Size([67, 67, 1]) \tbias shape: torch.Size([67])\n",
      "layer: Conv1d(96, 1, kernel_size=(7,), stride=(1,), padding=(3,)) \tweight shape: torch.Size([1, 67, 7]) \tbias shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"After pruning\")\n",
    "all_convs = []\n",
    "find_conv_layers(pruned_model.encoder.block, all_convs)\n",
    "find_conv_layers(pruned_model.decoder.model, all_convs)\n",
    "for conv in all_convs:\n",
    "    print(\"layer:\", conv, \"\\tweight shape:\", conv.weight.shape, \"\\tbias shape:\", conv.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress and Decompress + Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\audiotools\\ml\\layers\\base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.5656), tensor(1.3377), tensor(0.0080))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dac.utils import load_model\n",
    "from dac import DACFile\n",
    "from train import losses\n",
    "from dataclasses import dataclass\n",
    "\n",
    "ref_generator = load_model(\n",
    "    model_type=\"44khz\",\n",
    "    model_bitrate=\"8kbps\",\n",
    "    tag=\"latest\",\n",
    "    load_path=model_path,\n",
    ")\n",
    "\n",
    "audio_file_path = \"../samples/environmental_0000.wav\"\n",
    "\n",
    "signal = AudioSignal(audio_file_path)\n",
    "\n",
    "artifact = ref_generator.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "recons = ref_generator.decompress(artifact, verbose=False)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "x = signal.clone().resample(44100)\n",
    "y = recons.clone().resample(44100)\n",
    "mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5656), tensor(1.3377), tensor(0.0080))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_wn(ref_generator.encoder.block)\n",
    "remove_wn(ref_generator.decoder.model)\n",
    "\n",
    "artifact = ref_generator.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "recons = ref_generator.decompress(artifact, verbose=False)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "x = signal.clone().resample(44100)\n",
    "y = recons.clone().resample(44100)\n",
    "mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.4438), tensor(9.9672), tensor(0.1972))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_model = apply_channel_sorting(ref_generator)\n",
    "artifact = sorted_model.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "recons = sorted_model.decompress(artifact, verbose=False)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "x = signal.clone().resample(44100)\n",
    "y = recons.clone().resample(44100)\n",
    "mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)\n",
    "\n",
    "# with sorting snake1d parameters: (tensor(5.9051), tensor(9.7172), tensor(0.1575))\n",
    "# without sorting snake1d parameters: (tensor(5.7267), tensor(9.3324), tensor(0.1360))\n",
    "\n",
    "# does not work because of residual nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_pruning_ratio = 0.3\n",
    "# pruned_model = channel_prune(sorted_model, channel_pruning_ratio)\n",
    "\n",
    "# artifact = pruned_model.compress(signal, win_duration=5.0, verbose=False)\n",
    "\n",
    "# recons = pruned_model.decompress(artifact, verbose=False)\n",
    "\n",
    "# waveform_loss = losses.L1Loss()\n",
    "# stft_loss = losses.MultiScaleSTFTLoss()\n",
    "# mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "# x = signal.clone().resample(44100)\n",
    "# y = recons.clone().resample(44100)\n",
    "# mel_loss(x, y), stft_loss(x, y), waveform_loss(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Pruning Only in Residual Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\audiotools\\ml\\layers\\base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "c:\\Users\\Chenk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\")\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_residual_nets(layers, residual_nets):\n",
    "    for idx, layer in enumerate(layers):\n",
    "        if isinstance(layer, ResidualUnit):\n",
    "            # print(idx, layer)\n",
    "            residual_nets.append(layer)\n",
    "        elif hasattr(layer, 'block'):\n",
    "            find_residual_nets(layer.block, residual_nets)\n",
    "\n",
    "remove_wn(model.encoder.block)\n",
    "remove_wn(model.decoder.model)\n",
    "\n",
    "encoder_residual_nets = []\n",
    "decoder_residual_nets = []\n",
    "\n",
    "find_residual_nets(model.encoder.block, encoder_residual_nets)\n",
    "find_residual_nets(model.decoder.model, decoder_residual_nets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def apply_channel_sorting_resnet_only(model):\n",
    "    # fetch all the resnet from the model\n",
    "    all_resnets = []\n",
    "    find_residual_nets(model.encoder.block, all_resnets)\n",
    "    find_residual_nets(model.decoder.model, all_resnets)\n",
    "    # iterate through conv layers\n",
    "    for resnet in all_resnets:\n",
    "        # each channel sorting index, we need to apply it to:\n",
    "        # - the output dimension of the previous conv\n",
    "        # - the input dimension of the next conv (we compute importance here)\n",
    "        prev_snake, prev_conv, next_snake, next_conv = resnet.block\n",
    "        # note that we always compute the importance according to input channels\n",
    "        if (isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            importance = get_input_channel_importance_convtranspose1d(next_conv.weight)\n",
    "        else:\n",
    "            importance = get_input_channel_importance_conv1d(next_conv.weight)\n",
    "        # sorting from large to small\n",
    "        sort_idx = torch.argsort(importance, descending=True)\n",
    "        \n",
    "        # apply to the next conv input\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 0, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 0, sort_idx))\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight.copy_(torch.index_select(prev_conv.weight.detach(), 1, sort_idx))\n",
    "            next_conv.weight.copy_(torch.index_select(next_conv.weight.detach(), 1, sort_idx))\n",
    "\n",
    "        prev_conv.bias.copy_(torch.index_select(prev_conv.bias.detach(), 0, sort_idx))\n",
    "        \n",
    "        next_snake.alpha.data = torch.index_select(next_snake.alpha.data, 1, sort_idx)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_prune_model_resnet_only(model, prune_ratio):\n",
    "    # sanity check of provided prune_ratio\n",
    "    assert isinstance(prune_ratio, (float, list))\n",
    "    # fetch all the resnet from the model\n",
    "    all_resnets = []\n",
    "    find_residual_nets(model.encoder.block, all_resnets)\n",
    "    find_residual_nets(model.decoder.model, all_resnets)\n",
    "    n_resnets = len(all_resnets)\n",
    "\n",
    "    if isinstance(prune_ratio, list):\n",
    "        assert len(prune_ratio) == n_resnets\n",
    "    else:  # convert float to list\n",
    "        prune_ratio = [prune_ratio] * (n_resnets)\n",
    "\n",
    "    for resnet, p_ratio in zip(all_resnets, prune_ratio):\n",
    "        prev_snake, prev_conv, next_snake, next_conv = resnet.block\n",
    "        original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "        n_keep = get_num_channels_to_keep(original_channels, p_ratio)\n",
    "\n",
    "        if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight= nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "        elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "            prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "            next_conv.weight = nn.Parameter(next_conv.weight.detach()[:n_keep])\n",
    "        elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "            prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "            next_conv.weight = nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "        prev_conv.bias = nn.Parameter(prev_conv.bias.detach()[:n_keep])\n",
    "\n",
    "        next_snake.alpha = nn.Parameter(next_snake.alpha.data.detach()[:, :n_keep, :])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Losses\n",
      "mel_loss tensor(0.5656)\n",
      "stft_loss tensor(1.3377)\n",
      "waveform_loss tensor(0.0080)\n",
      "\n",
      "Pruned Losses\n",
      "mel_loss tensor(3.3208)\n",
      "stft_loss tensor(3.3100)\n",
      "waveform_loss tensor(0.0239)\n"
     ]
    }
   ],
   "source": [
    "from dac.utils import load_model\n",
    "from dac import DACFile\n",
    "from train import losses\n",
    "from dataclasses import dataclass\n",
    "\n",
    "ref_generator = load_model(\n",
    "    model_type=\"44khz\",\n",
    "    model_bitrate=\"8kbps\",\n",
    "    tag=\"latest\",\n",
    "    load_path=model_path,\n",
    ")\n",
    "\n",
    "audio_file_path = \"../samples/environmental_0000.wav\"\n",
    "\n",
    "signal = AudioSignal(audio_file_path)\n",
    "x = signal.clone().resample(44100)\n",
    "\n",
    "waveform_loss = losses.L1Loss()\n",
    "stft_loss = losses.MultiScaleSTFTLoss()\n",
    "mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "original_artifact = ref_generator.compress(signal, win_duration=5.0, verbose=False)\n",
    "original_recons = ref_generator.decompress(original_artifact, verbose=False)\n",
    "original_y = original_recons.clone().resample(44100)\n",
    "\n",
    "remove_wn(ref_generator.encoder.block)\n",
    "remove_wn(ref_generator.decoder.model)\n",
    "\n",
    "sorted_model = apply_channel_sorting_resnet_only(ref_generator)\n",
    "sorted_artifact = sorted_model.compress(signal, win_duration=5.0, verbose=False)\n",
    "sorted_recons = sorted_model.decompress(sorted_artifact, verbose=False)\n",
    "sorted_y = sorted_recons.clone().resample(44100)\n",
    "\n",
    "assert(abs(mel_loss(x, original_y) - mel_loss(x, sorted_y)) < 0.01)\n",
    "assert(abs(stft_loss(x, original_y) - stft_loss(x, sorted_y)) < 0.01)\n",
    "assert(abs(waveform_loss(x, original_y) - waveform_loss(x, sorted_y)) < 0.01)\n",
    "\n",
    "pruned_model = channel_prune_model_resnet_only(ref_generator, 0.3)\n",
    "pruned_artifact = pruned_model.compress(signal, win_duration=5.0, verbose=False)\n",
    "pruned_recons = pruned_model.decompress(pruned_artifact, verbose=False)\n",
    "pruned_y = pruned_recons.clone().resample(44100)\n",
    "\n",
    "print(\"Original Losses\")\n",
    "print(\"mel_loss\", mel_loss(x, original_y))\n",
    "print(\"stft_loss\", stft_loss(x, original_y))\n",
    "print(\"waveform_loss\", waveform_loss(x, original_y))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Pruned Losses\")\n",
    "print(\"mel_loss\", mel_loss(x, pruned_y))\n",
    "print(\"stft_loss\", stft_loss(x, pruned_y))\n",
    "print(\"waveform_loss\", waveform_loss(x, pruned_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5977), tensor(1.6659), tensor(0.0182))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audiotools.core import util\n",
    "\n",
    "def eval(model, dataset_path):\n",
    "    audio_files = util.find_audio(dataset_path)\n",
    "    waveform_loss = losses.L1Loss()\n",
    "    stft_loss = losses.MultiScaleSTFTLoss()\n",
    "    mel_loss = losses.MelSpectrogramLoss()\n",
    "    waveform_loss_sum = stft_loss_sum = mel_loss_sum = 0\n",
    "    for audio_file in audio_files:\n",
    "        signal = AudioSignal(audio_file)\n",
    "        x = signal.clone().resample(44100)\n",
    "        model_artifact = model.compress(signal, win_duration=12.0, verbose=False)\n",
    "        model_recons = model.decompress(model_artifact, verbose=False)\n",
    "        y = model_recons.clone().resample(44100)\n",
    "        waveform_loss_sum += waveform_loss(x, y)\n",
    "        stft_loss_sum += stft_loss(x, y)\n",
    "        mel_loss_sum += mel_loss(x, y)\n",
    "    return (mel_loss_sum / len(audio_files), stft_loss_sum / len(audio_files), waveform_loss_sum / len(audio_files))\n",
    "\n",
    "eval(model, \"../samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Pruning Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def uniform_sparsity_testing(model_path, audio_file_path, channel_pruning_ratios):\n",
    "    mel_losses = []\n",
    "    stft_losses = []\n",
    "    waveform_losses = []\n",
    "\n",
    "    waveform_loss = losses.L1Loss()\n",
    "    stft_loss = losses.MultiScaleSTFTLoss()\n",
    "    mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "    for channel_pruning_ratio in tqdm(channel_pruning_ratios):\n",
    "        model = dac.DAC.load(model_path)\n",
    "\n",
    "        remove_wn(model.encoder.block)\n",
    "        remove_wn(model.decoder.model)\n",
    "\n",
    "        sorted_model = apply_channel_sorting_resnet_only(model)\n",
    "        pruned_model = channel_prune_model_resnet_only(sorted_model, channel_pruning_ratio)\n",
    "\n",
    "        ml, sl, wl = eval(pruned_model, audio_file_path)\n",
    "\n",
    "        mel_losses.append(ml)\n",
    "        stft_losses.append(sl)\n",
    "        waveform_losses.append(wl)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot mel and stft losses on the primary axis\n",
    "    ax1.plot(channel_pruning_ratios, mel_losses, label='Mel Loss', color='tab:blue')\n",
    "    ax1.plot(channel_pruning_ratios, stft_losses, label='STFT Loss', color='tab:orange')\n",
    "\n",
    "    ax1.set_xlabel('Channel Pruning Ratio')\n",
    "    ax1.set_ylabel('Loss', color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Create a secondary axis for waveform losses\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(channel_pruning_ratios, waveform_losses, label='Waveform Loss', color='tab:green')\n",
    "    ax2.set_ylabel('Waveform Loss', color='tab:green')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "    # Add a legend that combines the two axes\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.title('Losses for Different (Uniform) Channel Pruning Ratios')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"../samples\"\n",
    "channel_pruning_ratios = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "uniform_sparsity_testing(model_path, audio_file_path, channel_pruning_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity for Each Residual Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def sensitivity_scan(model_path, audio_file_path, scan_step=0.1, scan_start=0.1, scan_end=1.0):\n",
    "    model = dac.DAC.load(model_path)\n",
    "    apply_channel_sorting_resnet_only(model)\n",
    "\n",
    "    remove_wn(model.encoder.block)\n",
    "    remove_wn(model.decoder.model)\n",
    "\n",
    "    waveform_loss = losses.L1Loss()\n",
    "    stft_loss = losses.MultiScaleSTFTLoss()\n",
    "    mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "    sparsities = np.arange(start=scan_start, stop=scan_end, step=scan_step)\n",
    "\n",
    "    encoder_resnets = []\n",
    "    encoder_mel_losses = []\n",
    "    encoder_stft_losses = []\n",
    "    encoder_waveform_losses = []\n",
    "    find_residual_nets(model.encoder.block, encoder_resnets)\n",
    "    \n",
    "    for i_resnet, resnet in enumerate(encoder_resnets):\n",
    "        prev_snake, prev_conv, next_snake, next_conv = resnet.block\n",
    "        prev_snake_alpha_clone, prev_conv_weight_clone, prev_conv_bias_clone, next_snake_alpha_clone, next_conv_weight_clone = prev_snake.alpha.detach().clone(), prev_conv.weight.detach().clone(), prev_conv.bias.detach().clone(), next_snake.alpha.detach().clone(), next_conv.weight.detach().clone()\n",
    "        mel_losses = []\n",
    "        stft_losses = []\n",
    "        waveform_losses = []\n",
    "        for sparsity in tqdm(sparsities, desc=f'Encoder Residual Units: scanning {i_resnet}/{len(encoder_resnets)} weight'):\n",
    "            # apply channel pruning using sparsity\n",
    "            original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "            n_keep = get_num_channels_to_keep(original_channels, sparsity)\n",
    "\n",
    "            if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight= nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "            elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:n_keep])\n",
    "            elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "            prev_conv.bias = nn.Parameter(prev_conv.bias.detach()[:n_keep])\n",
    "\n",
    "            next_snake.alpha = nn.Parameter(next_snake.alpha.data.detach()[:, :n_keep, :])\n",
    "\n",
    "            model_mel_loss, model_stft_loss, model_waveform_loss =  eval(model, audio_file_path)\n",
    "\n",
    "            mel_losses.append(model_mel_loss)\n",
    "            stft_losses.append(model_stft_loss)\n",
    "            waveform_losses.append(model_waveform_loss)\n",
    "\n",
    "            # restore \n",
    "            prev_conv.weight = nn.Parameter(prev_conv_weight_clone)\n",
    "            next_conv.weight = nn.Parameter(next_conv_weight_clone)\n",
    "            prev_conv.bias = nn.Parameter(prev_conv_bias_clone)\n",
    "            next_snake.alpha = nn.Parameter(next_snake_alpha_clone.data)\n",
    "\n",
    "        encoder_mel_losses.append(mel_loss)\n",
    "        encoder_stft_losses.append(stft_loss)\n",
    "        encoder_waveform_losses.append(waveform_loss)\n",
    "\n",
    "    decoder_resnets = []\n",
    "    decoder_mel_losses = []\n",
    "    decoder_stft_losses = []\n",
    "    decoder_waveform_losses = []\n",
    "    find_residual_nets(model.decoder.model, decoder_resnets)\n",
    "\n",
    "    for i_resnet, resnet in enumerate(decoder_resnets):\n",
    "        prev_snake, prev_conv, next_snake, next_conv = resnet.block\n",
    "        prev_snake_alpha_clone, prev_conv_weight_clone, prev_conv_bias_clone, next_snake_alpha_clone, next_conv_weight_clone = prev_snake.alpha.detach().clone(), prev_conv.weight.detach().clone(), prev_conv.bias.detach().clone(), next_snake.alpha.detach().clone(), next_conv.weight.detach().clone()\n",
    "        mel_losses = []\n",
    "        stft_losses = []\n",
    "        waveform_losses = []\n",
    "        for sparsity in tqdm(sparsities, desc=f'Decoder Residual Units: scanning {i_resnet}/{len(decoder_resnets)} weight'):\n",
    "            # apply channel pruning using sparsity\n",
    "            original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "            n_keep = get_num_channels_to_keep(original_channels, sparsity)\n",
    "\n",
    "            if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight= nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "            elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:n_keep])\n",
    "            elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "            prev_conv.bias = nn.Parameter(prev_conv.bias.detach()[:n_keep])\n",
    "\n",
    "            next_snake.alpha = nn.Parameter(next_snake.alpha.data.detach()[:, :n_keep, :])\n",
    "\n",
    "            artifact = model.compress(signal.clone(), win_duration=5.0, verbose=False)\n",
    "            recons = model.decompress(artifact, verbose=False)\n",
    "            y = recons.clone().resample(44100)\n",
    "\n",
    "            mel_losses.append(mel_loss(x, y))\n",
    "            stft_losses.append(stft_loss(x, y))\n",
    "            waveform_losses.append(waveform_loss(x, y))\n",
    "\n",
    "            # restore \n",
    "            prev_conv.weight = nn.Parameter(prev_conv_weight_clone)\n",
    "            next_conv.weight = nn.Parameter(next_conv_weight_clone)\n",
    "            prev_conv.bias = nn.Parameter(prev_conv_bias_clone)\n",
    "            next_snake.alpha = nn.Parameter(next_snake_alpha_clone.data)\n",
    "\n",
    "        decoder_mel_losses.append(mel_loss)\n",
    "        decoder_stft_losses.append(stft_loss)\n",
    "        decoder_waveform_losses.append(waveform_loss)\n",
    "\n",
    "    return sparsities, encoder_mel_losses, encoder_stft_losses, encoder_waveform_losses, decoder_mel_losses, decoder_stft_losses, decoder_waveform_losses\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def sensitivity_scan(model_path, audio_file_path, scan_step=0.1, scan_start=0.1, scan_end=1.0):\n",
    "    model = dac.DAC.load(model_path)\n",
    "    apply_channel_sorting_resnet_only(model)\n",
    "\n",
    "    remove_wn(model.encoder.block)\n",
    "    remove_wn(model.decoder.model)\n",
    "\n",
    "    waveform_loss = losses.L1Loss()\n",
    "    stft_loss = losses.MultiScaleSTFTLoss()\n",
    "    mel_loss = losses.MelSpectrogramLoss()\n",
    "\n",
    "    sparsities = np.arange(start=scan_start, stop=scan_end, step=scan_step)\n",
    "\n",
    "    all_resnets = []\n",
    "    all_mel_losses = []\n",
    "    all_stft_losses = []\n",
    "    all_waveform_losses = []\n",
    "    find_residual_nets(model.encoder.block, all_resnets)\n",
    "    find_residual_nets(model.decoder.model, all_resnets)\n",
    "    \n",
    "    for i_resnet, resnet in enumerate(all_resnets):\n",
    "        prev_snake, prev_conv, next_snake, next_conv = resnet.block\n",
    "        prev_snake_alpha_clone, prev_conv_weight_clone, prev_conv_bias_clone, next_snake_alpha_clone, next_conv_weight_clone = prev_snake.alpha.detach().clone(), prev_conv.weight.detach().clone(), prev_conv.bias.detach().clone(), next_snake.alpha.detach().clone(), next_conv.weight.detach().clone()\n",
    "        mel_losses = []\n",
    "        stft_losses = []\n",
    "        waveform_losses = []\n",
    "        for sparsity in tqdm(sparsities, desc=f'scanning {i_resnet}/{len(all_resnets)} weight'):\n",
    "            # apply channel pruning using sparsity\n",
    "            original_channels = prev_conv.out_channels  # same as next_conv.in_channels\n",
    "            n_keep = get_num_channels_to_keep(original_channels, sparsity)\n",
    "\n",
    "            if (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight= nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "            elif (isinstance(prev_conv, nn.Conv1d) and isinstance(next_conv, nn.ConvTranspose1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:n_keep])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:n_keep])\n",
    "            elif (isinstance(prev_conv, nn.ConvTranspose1d) and isinstance(next_conv, nn.Conv1d)):\n",
    "                prev_conv.weight = nn.Parameter(prev_conv.weight.detach()[:, :n_keep, :])\n",
    "                next_conv.weight = nn.Parameter(next_conv.weight.detach()[:, :n_keep, :])\n",
    "\n",
    "            prev_conv.bias = nn.Parameter(prev_conv.bias.detach()[:n_keep])\n",
    "\n",
    "            next_snake.alpha = nn.Parameter(next_snake.alpha.data.detach()[:, :n_keep, :])\n",
    "\n",
    "            model_mel_loss, model_stft_loss, model_waveform_loss = eval(model, audio_file_path)\n",
    "\n",
    "            mel_losses.append(model_mel_loss)\n",
    "            stft_losses.append(model_stft_loss)\n",
    "            waveform_losses.append(model_waveform_loss)\n",
    "\n",
    "            # restore \n",
    "            prev_conv.weight = nn.Parameter(prev_conv_weight_clone)\n",
    "            next_conv.weight = nn.Parameter(next_conv_weight_clone)\n",
    "            prev_conv.bias = nn.Parameter(prev_conv_bias_clone)\n",
    "            next_snake.alpha = nn.Parameter(next_snake_alpha_clone.data)\n",
    "\n",
    "        all_mel_losses.append(mel_loss)\n",
    "        all_stft_losses.append(stft_loss)\n",
    "        all_waveform_losses.append(waveform_loss)\n",
    "\n",
    "    return sparsities, all_mel_losses, all_stft_losses, all_waveform_losses\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsities, mel_losses, stft_losses, waveform_losses = sensitivity_scan(model_path, audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_sensitivity(sparsities, mel_losses, original_mel_loss, save_path=None):\n",
    "    fig, axes = plt.subplots(3, int(math.ceil(len(mel_losses) / 3)),figsize=(15,8))\n",
    "    five_pct_increase = 1.05 * original_mel_loss\n",
    "    ten_pct_increase = 1.1 * original_mel_loss\n",
    "    twenty_five_pct_increase = 1.25 * original_mel_loss\n",
    "    fifty_pct_increase = 1.5 * original_mel_loss\n",
    "    one_hundred_pct_increase = 2 * original_mel_loss\n",
    "    axes = axes.ravel()\n",
    "    for idx, mel_loss in enumerate(mel_losses):\n",
    "        ax = axes[idx]\n",
    "        curve = ax.plot(sparsities, mel_loss)\n",
    "        line1 = ax.plot(sparsities, [five_pct_increase] * len(sparsities))\n",
    "        line2 = ax.plot(sparsities, [ten_pct_increase] * len(sparsities))\n",
    "        line3 = ax.plot(sparsities, [twenty_five_pct_increase] * len(sparsities))\n",
    "        line4 = ax.plot(sparsities, [fifty_pct_increase] * len(sparsities))\n",
    "        line5 = ax.plot(sparsities, [one_hundred_pct_increase] * len(sparsities))\n",
    "        ax.set_xticks(np.arange(start=0.1, stop=1.0, step=0.1))\n",
    "        ax.set_title(f\"Residual Net {idx}\")\n",
    "        ax.set_xlabel('sparsity')\n",
    "        ax.set_ylabel('mel loss')\n",
    "        ax.legend([\n",
    "            'mel loss after pruning',\n",
    "            '5pct increase of original model mel loss'\n",
    "            '10pct increase of original model mel loss'\n",
    "            '25pct increase of original model mel loss'\n",
    "            '50pct increase of original model mel loss'\n",
    "            '100pct increase of original model mel loss'\n",
    "        ])\n",
    "        ax.grid(axis='x')\n",
    "    fig.suptitle('Sensitivity Curves: Mel Loss vs. Pruning Sparsity')\n",
    "    fig.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
